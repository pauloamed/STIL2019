
>> Initializing GSD dataset
>>> Started loading dataset
<<< Finished loading dataset
>>> Started parsing data from dataset
<<< Finished parsing data from dataset
>>> Started building tag dict for dataset
<<< Finished building tag dict for dataset
<< Finished initializing GSD dataset


>> Building char dict...
>>> Started extracting chars from GSD dataset
<<< Finished extracting chars from GSD dataset
<< Finished building dicts!


>> Started preparing GSD dataset
<< Finished preparing GSD dataset

=================================================================
GSD Dataset
Train dataset #sents: 9664 #words: 255755
Val dataset #sents: 1210 #words: 32129
Test dataset #sents: 1204 #words: 31496
Tag set: [BOS, EOS, ADJ, ADP, ADV, AUX, CCONJ, DET, NOUN, NUM, PART, PRON, PROPN, PUNCT, SYM, VERB, X]
=================================================================

POSTagger(
  (charBILSTM): CharBILSTM(
    (char_embeddings_table): Embedding(192, 70, padding_idx=0)
    (bilstm): LSTM(70, 350, batch_first=True, bidirectional=True)
    (projection_layer): Linear(in_features=700, out_features=350, bias=True)
    (dropout): Dropout(p=0.1)
  )
  (wordBILSTM1): WordBILSTM(
    (bilstm): LSTM(350, 350, batch_first=True, bidirectional=True)
    (projection_layer): Linear(in_features=700, out_features=350, bias=True)
    (dropout): Dropout(p=0.2)
  )
  (wordBILSTM2): WordBILSTM(
    (bilstm): LSTM(350, 350, batch_first=True, bidirectional=True)
    (projection_layer): Linear(in_features=700, out_features=350, bias=True)
    (dropout): Dropout(p=0.2)
  )
  (tag_bilstm): LSTM(350, 150, batch_first=True, bidirectional=True)
  (classifiers): ModuleList(
    (0): Linear(in_features=300, out_features=17, bias=True)
  )
  (dropout): Dropout(p=0.4)
)
train: batch_size=32, policy=visconde: 100% 302/302 [02:13<00:00,  2.24it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.74it/s]

=======================================================================================
Epoch: 0 	 Learning Rate: 1.000	Total Training Loss: 250.747565 	Total Validation Loss: 790.862489 	 Duration: 144.065
>> Dataset GSD:	Training Loss: 250.747565	Validation Loss:790.862489
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (inf --> 790.862489).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.37it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.74it/s]

=======================================================================================
Epoch: 1 	 Learning Rate: 1.000	Total Training Loss: 115.909456 	Total Validation Loss: 471.596338 	 Duration: 141.038
>> Dataset GSD:	Training Loss: 115.909456	Validation Loss:471.596338
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (790.862489 --> 471.596338).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:09<00:00,  2.32it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.49it/s]

=======================================================================================
Epoch: 2 	 Learning Rate: 1.000	Total Training Loss: 77.752274 	Total Validation Loss: 359.594194 	 Duration: 140.189
>> Dataset GSD:	Training Loss: 77.752274	Validation Loss:359.594194
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (471.596338 --> 359.594194).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:09<00:00,  2.36it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.56it/s]

=======================================================================================
Epoch: 3 	 Learning Rate: 1.000	Total Training Loss: 61.712377 	Total Validation Loss: 289.019855 	 Duration: 139.857
>> Dataset GSD:	Training Loss: 61.712377	Validation Loss:289.019855
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (359.594194 --> 289.019855).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:09<00:00,  2.49it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.26it/s]

=======================================================================================
Epoch: 4 	 Learning Rate: 1.000	Total Training Loss: 51.637787 	Total Validation Loss: 248.533629 	 Duration: 140.145
>> Dataset GSD:	Training Loss: 51.637787	Validation Loss:248.533629
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (289.019855 --> 248.533629).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.44it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.40it/s]

=======================================================================================
Epoch: 5 	 Learning Rate: 1.000	Total Training Loss: 44.953595 	Total Validation Loss: 218.919663 	 Duration: 139.744
>> Dataset GSD:	Training Loss: 44.953595	Validation Loss:218.919663
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (248.533629 --> 218.919663).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.30it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.61it/s]

=======================================================================================
Epoch: 6 	 Learning Rate: 1.000	Total Training Loss: 40.048984 	Total Validation Loss: 193.031271 	 Duration: 139.483
>> Dataset GSD:	Training Loss: 40.048984	Validation Loss:193.031271
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (218.919663 --> 193.031271).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.31it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.50it/s]

=======================================================================================
Epoch: 7 	 Learning Rate: 1.000	Total Training Loss: 36.037743 	Total Validation Loss: 176.200283 	 Duration: 139.582
>> Dataset GSD:	Training Loss: 36.037743	Validation Loss:176.200283
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (193.031271 --> 176.200283).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.46it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.75it/s]

=======================================================================================
Epoch: 8 	 Learning Rate: 1.000	Total Training Loss: 32.766870 	Total Validation Loss: 173.480299 	 Duration: 139.480
>> Dataset GSD:	Training Loss: 32.766870	Validation Loss:173.480299
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (176.200283 --> 173.480299).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.45it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.35it/s]

=======================================================================================
Epoch: 9 	 Learning Rate: 1.000	Total Training Loss: 30.325950 	Total Validation Loss: 148.745238 	 Duration: 139.772
>> Dataset GSD:	Training Loss: 30.325950	Validation Loss:148.745238
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (173.480299 --> 148.745238).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.35it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.38it/s]

=======================================================================================
Epoch: 10 	 Learning Rate: 1.000	Total Training Loss: 28.256935 	Total Validation Loss: 142.177700 	 Duration: 139.348
>> Dataset GSD:	Training Loss: 28.256935	Validation Loss:142.177700
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (148.745238 --> 142.177700).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.40it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.22it/s]

=======================================================================================
Epoch: 11 	 Learning Rate: 1.000	Total Training Loss: 26.483378 	Total Validation Loss: 132.381446 	 Duration: 139.484
>> Dataset GSD:	Training Loss: 26.483378	Validation Loss:132.381446
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (142.177700 --> 132.381446).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.42it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.29it/s]

=======================================================================================
Epoch: 12 	 Learning Rate: 1.000	Total Training Loss: 25.136960 	Total Validation Loss: 126.750039 	 Duration: 139.637
>> Dataset GSD:	Training Loss: 25.136960	Validation Loss:126.750039
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (132.381446 --> 126.750039).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.32it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.37it/s]

=======================================================================================
Epoch: 13 	 Learning Rate: 1.000	Total Training Loss: 23.786603 	Total Validation Loss: 121.630920 	 Duration: 139.332
>> Dataset GSD:	Training Loss: 23.786603	Validation Loss:121.630920
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (126.750039 --> 121.630920).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.32it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.61it/s]

=======================================================================================
Epoch: 14 	 Learning Rate: 1.000	Total Training Loss: 22.635127 	Total Validation Loss: 123.960035 	 Duration: 139.173
>> Dataset GSD:	Training Loss: 22.635127	Validation Loss:123.960035
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.34it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.35it/s]

=======================================================================================
Epoch: 15 	 Learning Rate: 1.000	Total Training Loss: 21.836760 	Total Validation Loss: 113.637863 	 Duration: 139.251
>> Dataset GSD:	Training Loss: 21.836760	Validation Loss:113.637863
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (121.630920 --> 113.637863).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.49it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.25it/s]

=======================================================================================
Epoch: 16 	 Learning Rate: 1.000	Total Training Loss: 21.003901 	Total Validation Loss: 110.860776 	 Duration: 139.499
>> Dataset GSD:	Training Loss: 21.003901	Validation Loss:110.860776
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (113.637863 --> 110.860776).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.29it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.92it/s]

=======================================================================================
Epoch: 17 	 Learning Rate: 1.000	Total Training Loss: 20.239590 	Total Validation Loss: 105.401069 	 Duration: 138.894
>> Dataset GSD:	Training Loss: 20.239590	Validation Loss:105.401069
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (110.860776 --> 105.401069).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.45it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.17it/s]

=======================================================================================
Epoch: 18 	 Learning Rate: 1.000	Total Training Loss: 19.439320 	Total Validation Loss: 102.679582 	 Duration: 139.159
>> Dataset GSD:	Training Loss: 19.439320	Validation Loss:102.679582
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (105.401069 --> 102.679582).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.30it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.49it/s]

=======================================================================================
Epoch: 19 	 Learning Rate: 1.000	Total Training Loss: 19.103121 	Total Validation Loss: 100.754551 	 Duration: 139.180
>> Dataset GSD:	Training Loss: 19.103121	Validation Loss:100.754551
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (102.679582 --> 100.754551).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.42it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.65it/s]

=======================================================================================
Epoch: 20 	 Learning Rate: 1.000	Total Training Loss: 18.302552 	Total Validation Loss: 99.850504 	 Duration: 139.258
>> Dataset GSD:	Training Loss: 18.302552	Validation Loss:99.850504
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (100.754551 --> 99.850504).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.35it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.46it/s]

=======================================================================================
Epoch: 21 	 Learning Rate: 1.000	Total Training Loss: 17.891144 	Total Validation Loss: 95.301180 	 Duration: 139.150
>> Dataset GSD:	Training Loss: 17.891144	Validation Loss:95.301180
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (99.850504 --> 95.301180).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.34it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.61it/s]

=======================================================================================
Epoch: 22 	 Learning Rate: 1.000	Total Training Loss: 17.317701 	Total Validation Loss: 94.320373 	 Duration: 139.078
>> Dataset GSD:	Training Loss: 17.317701	Validation Loss:94.320373
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (95.301180 --> 94.320373).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.36it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.21it/s]

=======================================================================================
Epoch: 23 	 Learning Rate: 1.000	Total Training Loss: 16.898867 	Total Validation Loss: 92.489862 	 Duration: 139.144
>> Dataset GSD:	Training Loss: 16.898867	Validation Loss:92.489862
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (94.320373 --> 92.489862).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.46it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.80it/s]

=======================================================================================
Epoch: 24 	 Learning Rate: 1.000	Total Training Loss: 16.525894 	Total Validation Loss: 92.499458 	 Duration: 139.024
>> Dataset GSD:	Training Loss: 16.525894	Validation Loss:92.499458
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.31it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.10it/s]

=======================================================================================
Epoch: 25 	 Learning Rate: 1.000	Total Training Loss: 16.140782 	Total Validation Loss: 88.608603 	 Duration: 139.237
>> Dataset GSD:	Training Loss: 16.140782	Validation Loss:88.608603
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (92.489862 --> 88.608603).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.35it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.51it/s]

=======================================================================================
Epoch: 26 	 Learning Rate: 1.000	Total Training Loss: 15.731658 	Total Validation Loss: 89.554210 	 Duration: 138.882
>> Dataset GSD:	Training Loss: 15.731658	Validation Loss:89.554210
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:11<00:00,  2.40it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.44it/s]

=======================================================================================
Epoch: 27 	 Learning Rate: 1.000	Total Training Loss: 15.497907 	Total Validation Loss: 86.731365 	 Duration: 142.365
>> Dataset GSD:	Training Loss: 15.497907	Validation Loss:86.731365
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (88.608603 --> 86.731365).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.37it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.90it/s]

=======================================================================================
Epoch: 28 	 Learning Rate: 1.000	Total Training Loss: 15.106793 	Total Validation Loss: 87.281464 	 Duration: 141.338
>> Dataset GSD:	Training Loss: 15.106793	Validation Loss:87.281464
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.31it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.46it/s]

=======================================================================================
Epoch: 29 	 Learning Rate: 1.000	Total Training Loss: 14.697555 	Total Validation Loss: 83.834865 	 Duration: 141.363
>> Dataset GSD:	Training Loss: 14.697555	Validation Loss:83.834865
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (86.731365 --> 83.834865).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.41it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.88it/s]

=======================================================================================
Epoch: 30 	 Learning Rate: 1.000	Total Training Loss: 14.433728 	Total Validation Loss: 83.177529 	 Duration: 141.199
>> Dataset GSD:	Training Loss: 14.433728	Validation Loss:83.177529
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (83.834865 --> 83.177529).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.28it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.21it/s]

=======================================================================================
Epoch: 31 	 Learning Rate: 1.000	Total Training Loss: 14.164104 	Total Validation Loss: 82.026727 	 Duration: 141.371
>> Dataset GSD:	Training Loss: 14.164104	Validation Loss:82.026727
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (83.177529 --> 82.026727).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.37it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.12it/s]

=======================================================================================
Epoch: 32 	 Learning Rate: 1.000	Total Training Loss: 13.942063 	Total Validation Loss: 83.325748 	 Duration: 141.346
>> Dataset GSD:	Training Loss: 13.942063	Validation Loss:83.325748
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.37it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.26it/s]

=======================================================================================
Epoch: 33 	 Learning Rate: 1.000	Total Training Loss: 13.620747 	Total Validation Loss: 81.545677 	 Duration: 141.446
>> Dataset GSD:	Training Loss: 13.620747	Validation Loss:81.545677
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (82.026727 --> 81.545677).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:11<00:00,  2.31it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.81it/s]

=======================================================================================
Epoch: 34 	 Learning Rate: 1.000	Total Training Loss: 13.404589 	Total Validation Loss: 80.331163 	 Duration: 142.117
>> Dataset GSD:	Training Loss: 13.404589	Validation Loss:80.331163
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (81.545677 --> 80.331163).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:09<00:00,  2.36it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.96it/s]

=======================================================================================
Epoch: 35 	 Learning Rate: 1.000	Total Training Loss: 13.079489 	Total Validation Loss: 78.767991 	 Duration: 140.590
>> Dataset GSD:	Training Loss: 13.079489	Validation Loss:78.767991
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (80.331163 --> 78.767991).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.36it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.05it/s]

=======================================================================================
Epoch: 36 	 Learning Rate: 1.000	Total Training Loss: 12.968200 	Total Validation Loss: 79.547241 	 Duration: 141.409
>> Dataset GSD:	Training Loss: 12.968200	Validation Loss:79.547241
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:09<00:00,  2.34it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.05it/s]

=======================================================================================
Epoch: 37 	 Learning Rate: 1.000	Total Training Loss: 12.708573 	Total Validation Loss: 76.911370 	 Duration: 140.877
>> Dataset GSD:	Training Loss: 12.708573	Validation Loss:76.911370
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (78.767991 --> 76.911370).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.40it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.05it/s]

=======================================================================================
Epoch: 38 	 Learning Rate: 1.000	Total Training Loss: 12.456580 	Total Validation Loss: 78.469955 	 Duration: 141.272
>> Dataset GSD:	Training Loss: 12.456580	Validation Loss:78.469955
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.33it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.87it/s]

=======================================================================================
Epoch: 39 	 Learning Rate: 1.000	Total Training Loss: 12.217549 	Total Validation Loss: 76.747246 	 Duration: 141.090
>> Dataset GSD:	Training Loss: 12.217549	Validation Loss:76.747246
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (76.911370 --> 76.747246).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.32it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.03it/s]

=======================================================================================
Epoch: 40 	 Learning Rate: 1.000	Total Training Loss: 12.024684 	Total Validation Loss: 78.953017 	 Duration: 141.680
>> Dataset GSD:	Training Loss: 12.024684	Validation Loss:78.953017
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:13<00:00,  2.21it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:11<00:00, 109.41it/s]

=======================================================================================
Epoch: 41 	 Learning Rate: 1.000	Total Training Loss: 11.826413 	Total Validation Loss: 76.125942 	 Duration: 144.449
>> Dataset GSD:	Training Loss: 11.826413	Validation Loss:76.125942
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (76.747246 --> 76.125942).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:12<00:00,  2.41it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.75it/s]

=======================================================================================
Epoch: 42 	 Learning Rate: 1.000	Total Training Loss: 11.720129 	Total Validation Loss: 74.775195 	 Duration: 143.184
>> Dataset GSD:	Training Loss: 11.720129	Validation Loss:74.775195
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (76.125942 --> 74.775195).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.35it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.04it/s]

=======================================================================================
Epoch: 43 	 Learning Rate: 1.000	Total Training Loss: 11.533219 	Total Validation Loss: 76.094817 	 Duration: 141.073
>> Dataset GSD:	Training Loss: 11.533219	Validation Loss:76.094817
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.31it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.35it/s]

=======================================================================================
Epoch: 44 	 Learning Rate: 1.000	Total Training Loss: 11.317607 	Total Validation Loss: 72.837241 	 Duration: 141.434
>> Dataset GSD:	Training Loss: 11.317607	Validation Loss:72.837241
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (74.775195 --> 72.837241).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:10<00:00,  2.30it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 110.91it/s]

=======================================================================================
Epoch: 45 	 Learning Rate: 1.000	Total Training Loss: 11.243875 	Total Validation Loss: 74.495084 	 Duration: 141.102
>> Dataset GSD:	Training Loss: 11.243875	Validation Loss:74.495084
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.37it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.52it/s]

=======================================================================================
Epoch: 46 	 Learning Rate: 1.000	Total Training Loss: 11.049930 	Total Validation Loss: 73.720378 	 Duration: 139.517
>> Dataset GSD:	Training Loss: 11.049930	Validation Loss:73.720378
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.46it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.19it/s]

=======================================================================================
Epoch: 47 	 Learning Rate: 1.000	Total Training Loss: 10.878680 	Total Validation Loss: 73.964078 	 Duration: 139.012
>> Dataset GSD:	Training Loss: 10.878680	Validation Loss:73.964078
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.39it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.76it/s]

=======================================================================================
Epoch: 48 	 Learning Rate: 1.000	Total Training Loss: 10.619457 	Total Validation Loss: 73.133417 	 Duration: 138.958
>> Dataset GSD:	Training Loss: 10.619457	Validation Loss:73.133417
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.28it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 111.56it/s]

=======================================================================================
Epoch: 49 	 Learning Rate: 1.000	Total Training Loss: 10.614842 	Total Validation Loss: 73.834819 	 Duration: 139.274
>> Dataset GSD:	Training Loss: 10.614842	Validation Loss:73.834819
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:07<00:00,  2.25it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.76it/s]

=======================================================================================
Epoch: 50 	 Learning Rate: 1.000	Total Training Loss: 10.575933 	Total Validation Loss: 72.123532 	 Duration: 138.695
>> Dataset GSD:	Training Loss: 10.575933	Validation Loss:72.123532
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (72.837241 --> 72.123532).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.38it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.50it/s]

=======================================================================================
Epoch: 51 	 Learning Rate: 1.000	Total Training Loss: 10.259867 	Total Validation Loss: 72.752264 	 Duration: 139.275
>> Dataset GSD:	Training Loss: 10.259867	Validation Loss:72.752264
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:07<00:00,  2.48it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.60it/s]

=======================================================================================
Epoch: 52 	 Learning Rate: 1.000	Total Training Loss: 10.112553 	Total Validation Loss: 72.333929 	 Duration: 138.745
>> Dataset GSD:	Training Loss: 10.112553	Validation Loss:72.333929
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.32it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.00it/s]

=======================================================================================
Epoch: 53 	 Learning Rate: 1.000	Total Training Loss: 10.055854 	Total Validation Loss: 71.900228 	 Duration: 139.159
>> Dataset GSD:	Training Loss: 10.055854	Validation Loss:71.900228
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (72.123532 --> 71.900228).  Saving model ...
=======================================================================================
train: batch_size=32, policy=visconde: 100% 302/302 [02:08<00:00,  2.30it/s]
val: batch_size=1, policy=emilia: 100% 1210/1210 [00:10<00:00, 112.97it/s]

=======================================================================================
Epoch: 54 	 Learning Rate: 1.000	Total Training Loss: 9.840457 	Total Validation Loss: 71.820196 	 Duration: 138.719
>> Dataset GSD:	Training Loss: 9.840457	Validation Loss:71.820196
----------------------------------------------------------------------------------------
Comparing loss on ['GSD'] dataset(s)
Validation loss decreased (71.900228 --> 71.820196).  Saving model ...
=======================================================================================
test: batch_size=1, policy=emilia: 100% 1204/1204 [00:12<00:00, 96.73it/s] 

Test Accuracy (Overall): 97% (30627/31496)

Test Accuracy (on GSD Dataset): 97.24% (30627/31496)